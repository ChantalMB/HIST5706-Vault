---
fileType: HypothesisAnnotations
creationDate: 2021-09-20 
annotationDate: 2021-09-16
uri: https://cradledincaricature.com/2020/06/18/mary-dorothy-george/
---
# A machine that writes like Mary Dorothy George
URL: https://cradledincaricature.com/2020/06/18/mary-dorothy-george/

What ways do you think this uncoupling could be prevented? Or, alternatively, do you feel this is an inevitable consequence of digitization?

There could always be context regarding circumstance of production provided alongside legacy data that is converted from print when accessing the collection, but then eventually that context could also become a product of the time it was created in, couldn't it?
&mdash;[[]]

## Source 
> that data begins to become uncoupled from its circumstances of production.[^1]

[^1]: [A machine that writes like Mary Dorothy George](https://cradledincaricature.com/2020/06/18/mary-dorothy-george/) | [syndication link](tk) 

---
tags: 
links:  [[#data]] [[data creation]] [[digitization]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;This piece by Dr. James Baker details his experimentation with the machine learning tool GPT-2-- a text generating language model-- when it is applied to a corpus of  catalogue entries written by 20th century historian Mary Dorothy George. Baker's research on George involves analyzing how her [curatorial voice](https://curatorialvoice.github.io/) influences our understanding of the late-Georgian satirical prints she catalogued, thus this article walks us through both the creation process and performance of a simulated version of George's image descriptions with the goal of possibly discovering more about the themes and trends found in her work as they emerge within her automated writings.

As Baker delves into the technical elements of generative text alongside the historiographical debates surrounding knowledge production when analyzing the outputs of "simGeorge", he highlights the ethical qualms and faults that result from using large-scale language models both generally and for historical inquiry. 
&mdash;[[]]

## Source 
> [^1]

[^1]: [A machine that writes like Mary Dorothy George](https://cradledincaricature.com/2020/06/18/mary-dorothy-george/) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;From the perspective of a researcher, I understand Baker's discomfort about sharing the complete outputs of simGeorge to both keep the generated descriptions attached to the context they were created in and to avoid putting more hurtful "history" out in the wild (even if it's technically fake, the  impact of language is real). Yet as a reader, I'm intrigued to investigate the outputs myself, wondering if I too might be able to uncover some themes of George's work that might contribute to Baker's findings.

What consequences to you feel might result from the publication of these outputs? Do you disagree or agree with Baker's reasoning for not publishing the output of this experiment?
&mdash;[[]]

## Source 
>  but also before having investigated further its quieter, systemic, and pervasive oppressions.[^1]

[^1]: [A machine that writes like Mary Dorothy George](https://cradledincaricature.com/2020/06/18/mary-dorothy-george/) | [syndication link](tk) 

---
tags: 
links:  [[ethics]] [[data sharing]] [[knowledge production]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Okay this phrasing confused me so I just thought I'd translate for anyone who might also be confused at this point.

GPT-2 learns how to use individual words by looking at the context a word is used in in the text you train the model with ex if it repeatedly saw the sentence "I like cats", it would learn that the word "like" commonly appears after "I" but before "cats". 

So, this sentence is stating that the model will write in a similar fashion to the text it is trained with (in this article, MDG) because it's basically learning how to constructed sentences via that specific corpus, thus the output will likely have any stylistic quirks or common vocab that the author of the corpus possesses. The language model is *not* just repeating full sentences it has observed previously.
&mdash;[[]]

## Source 
> Instead, the model writes like the writing it has seen, but not in the same way as the writing it has seen.[^1]

[^1]: [A machine that writes like Mary Dorothy George](https://cradledincaricature.com/2020/06/18/mary-dorothy-george/) | [syndication link](tk) 

---
tags: 
links:  [[language model]] [[GPT-2]] [[technology]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Sort of a post-read question, but do you think that perhaps further experimentation with the settings may have been beneficial to the resulting output of simGeorge? How does one determine how much tweaking is too much when determining the ecological cost is also somewhat vague?
&mdash;[[]]

## Source 
> but not too much, the GPU time may carry no direct monetary ‘cost’ but it does incur an ecological cost[^1]

[^1]: [A machine that writes like Mary Dorothy George](https://cradledincaricature.com/2020/06/18/mary-dorothy-george/) | [syndication link](tk) 

---
tags: 
links:  [[environment]] [[ethics]] [[technology]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;The idea of trying to sort out the overtly discriminatory voice of late-Georgian satire from perhaps some of George's own discriminatory beliefs intrigues me. Does the language model make these subtleties more obvious or even harder to distinguish from one another?
&mdash;[[]]

## Source 
> because they are manifestations of language choices produced by the historically specific circumstances in which George’s labour took place[^1]

[^1]: [A machine that writes like Mary Dorothy George](https://cradledincaricature.com/2020/06/18/mary-dorothy-george/) | [syndication link](tk) 

---
tags: 
links:  [[language]] [[narrative]] [[context]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;

---------------------------------------------------------------------

# On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C
URL: https://dl.acm.org/doi/pdf/10.1145/3442188.3445922

## Source 
> environmental price of training anddeploying ever larger English LMs, when similar large-scale modelsaren’t being produced for Dhivehi or Sudanese Arabic?[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;## Source 
> Developing and shifting frames stand to be learned in incompleteways or lost in the big-ness of data used to train large LMs — particu-larly if the training data isn’t continually updated. [^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;## Source 
> But the training datafor LMs is only form; they do not have access to meaning. Therefore,claims about model abilities must be carefully characterized.[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;## Source 
> an LM is a systemfor haphazardly stitching together sequences of linguistic formsit has observed in its vast training data, according to probabilisticinformation about how they combine, but without any reference tomeaning: a stochastic parrot[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;## Source 
> As discussed in§4.1, simply turning to massive dataset size as a strategy for beinginclusive of diverse viewpoints is doomed to failure. [^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;## Source 
> For researchers workingwith LMs, value sensitive design is poised to help throughout thedevelopment process in identifying whose values are expressed andsupported through a technology and, subsequently, how a lack ofsupport might result in harm.[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Often, technologies are produced and enhance for the sake of progress and competition with other developers in the same field, and in the fast-paced world of the digital, there is rarely a moment of reflection to ask why certain technologies are being created or about the implications of their results. This article was produced by a collective of computational researchers involved in both academics and industry in order to discuss the often ignored pitfalls found within the rapidly growing development of language models. 

Not only do they succinctly explain the environmental and financial implications involved in creating language models who are trained on unfathomable (and by extension, undocumentable) amounts of data, in a conversation most relevant to humanists they discuss "the tendency of huge amounts of training data ingested from the Internet to encode hegemonic world-views, the tendency of LMs to amplify biases and other issues in the training data, and the tendency of researchers and other people to mistake LM-driven performance gains for actual natural language understanding." Further, they also provide solutions that can be applied to our work through careful data curation and documentation and allocating research effort to harm mitigation in such cases where LMs are necessary.

This article, in my opinion, is incredibly important to read for anyone engaging in work related to machine learning. The technical knowledge it provides is crucial to understanding the broader impact of work that uses such methods and how the results can be interpreted with understanding of the context in which the technology used was created. 
&mdash;[[]]

## Source 
> [^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[technology]] [[language model]] [[NLP]] [[methodology]] [[data]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;In the context of studying history using language models (ex [James Baker's article](https://cradledincaricature.com/2020/06/18/mary-dorothy-george/)), is this just imputing meaning or can synthetic text have meaning beyond just the sentences the LMs output?  
&mdash;[[]]

## Source 
> Furthermore, the tendency of human interlocutors to imputemeaning where there is none can mislead both NLP researchersand the general public into taking synthetic text as meaningful.[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[language]] [[analysis]] [[technology]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;How might equitable access affect what research is performed using these resource intensive tools?

As a starting point for my line of thought, I'm questioning who has the most access to these resources currently, and what kind of research are they choosing to perform?
&mdash;[[]]

## Source 
> They also urge governments toinvest in compute clouds to provide equitable access to researchers.[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[technology]] [[accessibility]] [[research]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;## Source 
> Even if populations who feel unwelcome in mainstream sites setup different fora for communication, these may be less likely to beincluded in training data for language models.[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Since we know that this model was primarily trained on english language content, I wonder how much the written voice of ESL speakers ended up being eliminated from the training data due to this parameter? 

What a computer might deem as unintelligible based on a series of instructions may actually be intelligible to a human reader. 
&mdash;[[]]

## Source 
>  filtering out docu-ments that previous work characterized as “unintelligible” [^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[data curation]] [[ethics]] [[automation]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;I wonder what perils may come with training a LM with oral histories. Conceptually this is an excellent way to add representation from marginalized communities, but how might the transcription process look from an area of research that is known to prioritize efficiency over accuracy?
&mdash;[[]]

## Source 
> For instance, one can take inspi-ration from movements to decolonize education by moving towardsoral histories due to the overrepresentation of colonial views intext [35, 76, 127[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[language model]] [[oral history]] [[representation]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;When dealing with historical topics, the documentation of our work and data is incredibly important not only so that we as historians are held accountable for any sort of bias that may be found in our work, but also because our work often deals with the origins of harmful views still held today.
&mdash;[[]]

## Source 
> While documentation allows for potential accountability [13, 52, 86],undocumented training data perpetuates harm without recourse.[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[methodology]] [[documentation]] [[ethics]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;This very much resembles the formation of the historical practice and archive. Like LMs, archives are filled with objects produced and deemed important by those in positions of privilege throughout history. Can you draw other parallels between the production of LMs and historical practice?
&mdash;[[]]

## Source 
>  As people in positions of privilegewith respect to a society’s racism, misogyny, ableism, etc., tendto be overrepresented in training data for LMs (as discussed in§4 above), this training data thus includes encoded biases, manyalready recognized as harmful[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[methodology]] [[archive]] [[curation]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Do you think a "pre-mortem" for digital history based projects would be useful for our practice? Do you already do something like this when doing historical work?
&mdash;[[]]

## Source 
> Frequently used inbusiness settings before the deployment of new products or projects,pre-mortem analyses center hypothetical failures and ask teammembers to reverse engineer previously unanticipated causes[^1]

[^1]: [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99COn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? "1F99C](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) | [syndication link](tk) 

---
tags: 
links:  [[practice]] [[methodology]] [[planning]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;

---------------------------------------------------------------------

# Enriching Historic Photography with Structured Data using Image Region Segmentation
URL: https://statsmaths.github.io/pdf/2020-enrich-photography.pdf

Just for fun, can you see what the computer is seeing in "false detection" images? I can absolutely see how the computer got "banana" from the 2nd image in that word's row.
&mdash;[[]]

## Source 
> The remaining categoriesseem to be all false detections. Many mistakes are hard to explain, such as the row of skateboard objects.[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;![ai-meme](https://i.imgur.com/talNLZv.jpg)
&mdash;[[]]

## Source 
> fourth mistakenly believes the two men in theframe are giraffes[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;## Source 
> By forgoingthe explicit creation of structured data, they avoid many ofthe pitfalls of the automated information extraction.[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Although these results are statistically excellent for an automated process, the fact that labels were not found for 100% of the images tells us that some images remain unlabelled and excluded from the linking of data that this project intended to create. 

If these auto-generated captions were released to the public, what would happen to these unlabelled images? They would likely still exist in the archive, but what would happen to their discoverability if they didn't work within the network of data generated between the labelled images? 
&mdash;[[]]

## Source 
> and labels were found for nearly99% of all images.[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Based on an earlier quote in this article, much of this project was based on finding a method of describing images that could "deploy directly in an archive."

After reading about the different ways images may be captioned and/or labelled, do you feel that any of these methods could be deployed in an archive without much if any human intervention, and be successful? 

If you *know* of any examples of this already happening, please share because I'd love to explore them!
&mdash;[[]]

## Source 
> offers a strategy for algo-rithmically enriching large corpora of photographic mate-1 Full replication code, data, and results are availableat: https://github.com/statsmaths/fsa_color_analysis.rials through structured data in order to facilitate access,discovery, and exploration within and across collections[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;In the context of this article, this issue is framed as an issue of incomplete or poorly crafted metadata resulting in a reduced ability to link data across collections; but how does this speak to accessibility in the digital archive?
&mdash;[[]]

## Source 
> In other words, captionsare written assuming that the reader will be able to lookat the object.[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  [[archive]] [[accessibility]] [[digitization]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Just for fun, can you see what the computer is seeing in "false detection" images? I can absolutely see how the computer got "banana" from the 2nd image in that word's row.
&mdash;[[]]

## Source 
> The remaining categoriesseem to be all false detections. Many mistakes are hard to explain, such as the row of skateboard objects.[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Although these results are statistically excellent for an automated process, the fact that labels were not found for 100% of the images tells us that some images remain unlabelled and excluded from the linking of data that this project intended to create. 

If these auto-generated captions were released to the public, what would happen to these unlabelled images? They would likely still exist in the archive, but what would happen to their discoverability if they didn't work within the network of data generated between the labelled images? 
&mdash;[[]]

## Source 
> and labels were found for nearly99% of all images.[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  [[technology]] [[metadata]] [[archive]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Based on an earlier quote in this article, much of this project was based on finding a method of describing images that could "deploy directly in an archive."

After reading about the different ways images may be captioned and/or labelled, do you feel that any of these methods could be deployed in an archive without much if any human intervention, and be successful? 

If you *know* of any examples of this already happening, please share because I'd love to explore them!
&mdash;[[]]

## Source 
> through structured data in order to facilitate access,discovery, and exploration within and across collections.[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  [[metadata]] [[data creation]] [[technology]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;![ai-meme](https://i.imgur.com/talNLZv.jpg)
&mdash;[[]]

## Source 
>  fourth mistakenly believes the two men in theframe are giraffes[^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;In this article, the central goal of Arnold and Tilton is exploring possible solutions to the challenge which GLAM institutions face of creating structured data that lends itself discovery and access on the web when it comes to the digitization process of large collections. They choose to focus on collections of historic photography which tend to lack structured data relating to the content of the image likely due to the amount of human labour involved in that particular process, and so  using computer vision to detect various components of an image they attempt to automatically generate structured data that describes the content of an image and allows like images to be linked within a collection through this data.

Arnold and Tilton's experiment with "image stuff segmentation" proves to be the most successful at identify image contents, which leads to the possibility of further developing this automated creation of metadata for imagery to encode a greater amount of detail on each detected region. But ultimately I concur with Kavita's thoughts on efficiency versus accuracy-- a significant takeaway from this article is that even the CV implementation that was the most accurate could not successfully label 100% of the images which could lead to certain parts of a collection being lost. 
&mdash;[[]]

## Source 
> [^1]

[^1]: [Enriching Historic Photography with Structured Data using Image Region Segmentation](https://statsmaths.github.io/pdf/2020-enrich-photography.pdf) | [syndication link](tk) 

---
tags: 
links:  [[technology]] [[computer vision]] [[metadata]] [[linked data]] [[accessibility]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;

---------------------------------------------------------------------

# Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice
URL: https://muse-jhu-edu.proxy.library.carleton.ca/article/777493

Out of curiosity, for those who have done research in-person at the LAC, what was your experience like? Did it match what Milligan is describing? 

I once went to look at a collection of (photo) negatives at LAC and even for that, rather than requesting the negative be developed by a member of the LAC staff, I just took a photo of all the negatives I thought might be relevant while they were sitting on the lightbox and then developed the photos myself later!
&mdash;[[]]

## Source 
> Today, when you visit lac or most other archives, you are more likely than not to see a historian or other patron using a digital camera to reproduce their material.[^1]

[^1]: [Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice](https://muse-jhu-edu.proxy.library.carleton.ca/article/777493) | [syndication link](tk) 

---
tags: 
links:  [[research]] [[digitization]] [[process]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;As you might notice if you choose to read the "On the Dangers of Stochastic Parrots" article-- which is a standard ACM science-y paper-- there is a huge amount of discussion regarding methodology and how the research cited in the paper came to be. Comparatively, in my 4yr undergrad history degree, only once do I recall thinking "wow I'm so impressed with how much this paper discusses methodology", and it turned out said paper, although centred on a historical topic, was published in a journal for "economics history", and 2 of the 3 authors were economists (the other was also an economist, but specifically studied economics history). 

Have you ever come across a history-related paper that discussed methodology in an in-depth manner? Do you feel this discussion was beneficial to you in any way or did it "disrupt the narrative" as this quote states? 
&mdash;[[]]

## Source 
> A co-authored 2017 white paper by twenty-four historians highlighted that the "experience of workshop participants has been that reviewers and editors frequently insist that methodological sections be cut or shortened to avoid disrupting the narrative."[^1]

[^1]: [Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice](https://muse-jhu-edu.proxy.library.carleton.ca/article/777493) | [syndication link](tk) 

---
tags: 
links:  [[methodology]] [[research]] [[publishing]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;What impact do you think citation standards have on this?

This article frequently discusses how many researchers work on tight deadlines; further, on top of these deadlines, many journals that researchers may be submitting articles to have their own outlined formatting which usually also specifies the style which references should be cited with. When it comes to digitized archives, there's often a lot of ambiguity about the "correct" way to cite these types of sources-- so, I wonder how much of this *not* happening is due to it simply being easier and faster to find out how to cite the original document rather than searching for this info, or asking how to correctly cite the digitized document and having to wait for a response?  
&mdash;[[]]

## Source 
> historians should make sure to cite the datasets that they are using and to not pretend that they are consulting original documents but, rather, to note that they obtained them via lac's website thanks to the efforts of colleagues in the DigiLab.[^1]

[^1]: [Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice](https://muse-jhu-edu.proxy.library.carleton.ca/article/777493) | [syndication link](tk) 

---
tags: 
links:  [[citation]] [[research]] [[digitization]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Using the aforementioned "highly-portable scanning solutions", I wonder if a happy medium could be achieved here?

Most portable scanners either function like cameras where there is some sort of memory card in the device which stores the scans to be downloaded later, or they connect directly to a device. Rather than having to go to a physical place to "properly" digitize their work, the latter group of historians could be provided a portable scanner by the archive upon arrival that would allow them to work in the manner they prefer, but also allow improved photo quality that could be shared with the archive post-session. Where would the budget come from to buy an appropriate number of portable scanners? That's another story...


&mdash;[[]]

## Source 
>  While some methodological historians who prefer to associate metadata with photographs in the archives may find DigiLab a quicker place to work in, others who focus on taking sheer volumes of photographs to work with entirely at home will find it slower.[^1]

[^1]: [Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice](https://muse-jhu-edu.proxy.library.carleton.ca/article/777493) | [syndication link](tk) 

---
tags: 
links:  [[digitization]] [[research]] [[metadata]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Is this surprising to anyone else? 

This study was published in Dec 2020, so I would've assumed that most researchers taking photos in the archive would be using their smartphones. I know very few people who own a digital camera presently, and I don't know how common it is to be able to get one on loan from the archive or institution a researcher is apart of?
&mdash;[[]]

## Source 
> Most historians are using a digital camera (some  [End Page 609]  sixty percent), but a not insubstantial number of them use their smartphones (approximately thirty-three percent)[^1]

[^1]: [Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice](https://muse-jhu-edu.proxy.library.carleton.ca/article/777493) | [syndication link](tk) 

---
tags: 
links:  [[technology]] [[digitization]] [[research]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;Why might it be that only smaller municipal archives tend to be the ones that ban digital photography of their collections?
&mdash;[[]]

## Source 
> of these websites, almost all made explicit mention of digital photography, and, for the most part, only small municipal archives expressly banned digital photography of their collections[^1]

[^1]: [Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice](https://muse-jhu-edu.proxy.library.carleton.ca/article/777493) | [syndication link](tk) 

---
tags: 
links:  
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;In this article, Dr. Ian Milligan looks at the changing practices of Canadian historians' work within the archive, primarily regarding the ways they spend time at the archive capturing information for their research. His survey specifically looked at the "digital method" many wouldn't consider to be a digital method at all-- the use of digital archival photography.

By comparing previous archival practices to the present, Milligan establishes a fundamental shift in how archival research is performed. Rather than the archive being the heart of historical labour-- a place where research was all at once curated, reflected upon, and written about-- as it once was, with the emergence of technologies such as digital cameras and smartphones, historical labour has become split between stages of collection at the archive and reflection at the office or home as engagement with the archive becomes mediated by a (literal) digital lens and documents previously only accessible physically at one facility become portable through a photographic capture. This rapidly evolving new methodology ultimately raises questions about the nature of historical work in our present; about what kind of training historians should receive, how digital archival photography changes the way which historical work is practiced, and how these technologies can ultimately be leveraged to benefit a larger number of researchers through support of formal digitization efforts.
&mdash;[[]]

## Source 
> [^1]

[^1]: [Project MUSE - We Are All Digital Now: Digital Photography and the Reshaping of Historical Practice](https://muse-jhu-edu.proxy.library.carleton.ca/article/777493) | [syndication link](tk) 

---
tags: 
links:  [[digitization]] [[methodology]] [[archive]] 
- broader terms (BT):  
- narrower terms (NT):  
- related terms (RT):  
connected ideas:  ;